{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f94b4d7-69b5-442b-a9e6-c6653fcb5aa3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fundamentals of Social Data Science \n",
    "\n",
    "Week 1. Day 3. Exercises from Chapter 3 of FSStDS \n",
    "\n",
    "Within your study pod discuss the following questions. Please submit an individual assignment by 12:30pm Monday, October 17, 2022 on Canvas. \n",
    "\n",
    "These assignments have two sets of questions. The top questions have answers already in them. The last question is for you to submit. That last question will be given written feedback via the teaching assistants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdf5e73-8712-42c6-b7a5-ec3040265e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "# RUN THIS CELL IF YOU HAVE THE KEY \n",
    "# This is what we use to create the sample answers as encrypted text\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "def encrypt(message: str, key: bytes) -> bytes:\n",
    "    return Fernet(key).encrypt(message.encode())\n",
    "\n",
    "def decrypt(token: bytes, key: bytes) -> str:\n",
    "    if not key: \n",
    "        return \"Hey now, why not try these on your own first?\"\n",
    "    return Fernet(key).decrypt(token).decode()\n",
    "\n",
    "# In case you're stuck or want to check your work, \n",
    "# uncomment the key and then run the sample answer cells. \n",
    "\n",
    "key = None\n",
    "\n",
    "# key = b'_beepbeepbeepbeep1234567890beepbeepbeepbeep=' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc99d8ef-0f7f-451e-ac04-a63420375604",
   "metadata": {},
   "source": [
    "# Shorter questions with answers\n",
    "\n",
    "These questions use a pre-chewed IMDB file of movies with over 10k votes on the platform. It's considerably smaller than the 760mb file of all movies. It should be available from Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bcf4aa-da92-4dca-9d3b-7e68a9e5bf82",
   "metadata": {},
   "source": [
    "## Step 1. Read in the file. \n",
    "\n",
    "The first thing is to read in the file, `\"imdb_over10k_votes_movies.csv\"`. This is a list of movies from IMDB that have more than 10,000 votes on their ratings. I have prepared this data from a data export freely available from IMDB. The code for how I did it is in the appendix to this formative. \n",
    "\n",
    "There's conicidentally also about 10k movies in this data set. A big number but not too unwieldy for a personal computer. Herein, we are just going to practice asking and answering questions about this data. Most of what we are going to do with these questions is rank, summarise, and compare. We might want to compare the runtimes of movies of different genres or ratings.\n",
    "\n",
    "To get you started, check that your DataFrame looks similar to the one here from this code. For the example answer I stored the file in an adjacent folder called `data`, so for me that is why the path looks like so. I similarly recommend you having a separate folder for your data just in a sibling folder to this one (rather than a 'subfolder' within this one). As in: \n",
    "\n",
    "~~~\n",
    "- FSDS\n",
    "  - Data\n",
    "    - imdb_over10k_votes_movies.csv\n",
    "  - Formatives\n",
    "    - SURNAME_INIT_WD21_w1formative_DataFramePratice.ipynb\n",
    "  - Summative \n",
    "  - Readings\n",
    "  etc...\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b059cac4-af19-4fa8-a6d4-befe9913965b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9694 entries, 0 to 9693\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   tconst          9694 non-null   object \n",
      " 1   primaryTitle    9694 non-null   object \n",
      " 2   originalTitle   9694 non-null   object \n",
      " 3   startYear       9694 non-null   int64  \n",
      " 4   runtimeMinutes  9694 non-null   int64  \n",
      " 5   averageRating   9694 non-null   float64\n",
      " 6   numVotes        9694 non-null   float64\n",
      " 7   genre1          9694 non-null   object \n",
      " 8   genre2          8840 non-null   object \n",
      " 9   genre3          6361 non-null   object \n",
      "dtypes: float64(2), int64(2), object(6)\n",
      "memory usage: 757.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Step 1 answer below (ensuring your file is in the right folder)\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "movie_dir = Path().cwd().parent / \"data\"\n",
    "movie_path = movie_dir / \"imdb_over10k_votes_movies.csv\"\n",
    "assert movie_path.exists(), \"File not found\"\n",
    "movie_df = pd.read_csv(movie_path)\n",
    "\n",
    "\n",
    "movie_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4815292c-05ef-426f-884b-bec049594c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = b'gAAAAABh6UcLaoFySY7xkY_0mmZk5vkcNgqUdZpLg1CW04bMW3E-pKGS2js4S19wn5ja0Z3jrkpzf6siH_x_5C0oj_rFHAuRnNXk_zyGKTtmkube7-Ha6uO9LEt3T6cHMPu4wXSmF1oLp5bja_HeQw5Xs0IDyTW5D3ZW_9acMPEOEPjOZ7-XrsKWXLkAdZLBxIY-c2JyfGX8fv7FRwkMEFz1H4hGKOhip77mFH_vMEhxCtChIE7EoSN5NqV9BaSm9gl4nYjNjvRLI93Q3aOV0sRVXXBlDE7GE6vcgvDmZL5wJLHTn1pJN6ZycN6iU5F10Sef6SwW9l1AO26U95O02b_U-hFaiLnMEw04_0VCay0ZG0Feuc9NuQVn9cs0B43am5XuIM9kAdlAOXUmmLw9YE-f8VB5877l1rnhBddp10yPtgFBr0pGYFfpzj_tZj48190xKLEd2R1CV5mngQqx557MDZ_9XSFCq3JG-IoEQqdkc_1nHEhkqS0NzfapMGgkQh1vMnIn4opLy-51iBp3SpRi0VsfPke_3PgvAoO6T-Ntrowf-nZtW-W2s8TJQ8pj6-OCTw3ti74TFyguenw2WbPCf-HzcnnabHbFa7NYkDcXoJSN7Dnxri9slpAp6iIk3hyAqWPhDZjyPv90eCjivKuCL63Y-mhEFEKhSziHm4cMpWF2fxyYJs3y69buaQqefNFTV9VMFeO9Dj-qTA1YUCFh5AU0R5eTOkWq7-hB6yh3Qmvy6ZbbU93gcEHc-nd8nLsTCvftODXZKgqkj5NjYrSK9VjtVSc3tGQ2w8b4mAre_ahQtq54fY1yFj6GF_5KByc6cOqiWwqKpNp6GifV6Z6KT0FVj6GujflT4JDry1a8JbmtrD6-wp7ONPQ2cJlQE5HL_wxcmyiY5nDkiXGQO27-obhsJaz5gDNFMfrZFZ18kHnwqFroZaj6ZvFVxLdnH-OddoNvUDg5_lr6XvEZj1z0FHSjPRI1mWL-5BeEbGyGqQAkoCN-vJYcx8KUiLwHaKtKhMwA99HoLgL-Avqi6jHWICdm96Ye0TVav55E0T_m5SFcWwr4huM='\n",
    "\n",
    "print(decrypt(ans, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad1901-1a63-4851-9c3e-2e5f326be980",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2. Learn about the data set. \n",
    "\n",
    "Below are some questions to ask about the data set. I have printed some answers. Your job is to fill in the values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73506cdc-24b7-428d-8521-a2d591ae199c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this data set are 9694 in total.\n",
      "The movie with the lowest rating is Cumali Ceber with a rating of 1.0.\n",
      "The movie with the highest rating is The Chaos Class with a rating of 9.3.\n"
     ]
    }
   ],
   "source": [
    "num_movies = len(movie_df)\n",
    "lowest_rating = movie_df[\"averageRating\"].min()\n",
    "lowest_rating_name = movie_df.sort_values(\"averageRating\", ascending=True).iloc[0][\"primaryTitle\"]\n",
    "highest_rating = movie_df[\"averageRating\"].max()\n",
    "highest_rating_name = movie_df.sort_values(\"averageRating\", ascending=False).iloc[0][\"primaryTitle\"]\n",
    "\n",
    "print(f\"In this data set are {num_movies} in total.\") \n",
    "print(f\"The movie with the lowest rating is {lowest_rating_name} with a rating of {lowest_rating}.\")\n",
    "print(f\"The movie with the highest rating is {highest_rating_name} with a rating of {highest_rating}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6997ae-cf16-43bb-8266-df33021b78b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = b'gAAAAABh6Uhn5K1CBvVi-kmnwLUj1bwYTgtNsO7BgdRlHigpsRPj3R60acHEg7b8HAPtidj6UY5j39MAPoXf24MkbtzLj--_RPj4KrNSWWODKIG4_KwmRUap3_u17SxklPscaOUOQkl_1NNjAZ4uh8nNe1u5Jbrgo6KtyUV54BNjrhkTx6rwi-1K-VbzL17TSEkARKI8z42xmZBVTl5rkPA_P6PdOy_pFisZjcYfplFVvHOe4A25xg_nGguMVtvC_4b9gOJzVZ-LGvwASUS115rokK3H4LtZtyjJUQyUuRpgfMfMaX-EhuUHxbBEvmovcdDePRRp_qUWH7_B7pYQ3wI6Y54vnEPZ6WyVC5x4KDpU7QtyozW_ziv0VT9fApTcfsn2BWEXMuUsDAChbXXxgDVv-Q02Jh12S9gLgJJsd-58jBar-wePIoGe5__5Dhx8OGPno1ACM-NTbmyj99C6Np8M-QLZVC2vnqgk0kQTNfIC992vq17FxUdWJvfxVnLVaxwsQxYaGnZ-54fCTo5EXoOCgBiOstanvdIIgWK2XRLBKQSYzb8QGTR4S04h3J2sdXkgs7AS_2Xkso9-HHlqdKBwhfz24rgFKR82Kl14IQq-lTXbwElIHCR5h6GY5x0V1YCyZoubsBPzYaGNPOig3wk7u4zpzGehs2EL94cLHz5XvDA-kSdWFfwoRmwipH5zuj0axp3QqSs2eXYZHy_v6QDvF5BXSWqv2MqkHxepG0cQtBVD5v7f95tgTQ8GOSwqyIomo-YfQog2LLAIMw5qrSaM7_WG67Z2cf5fjDWrSNGv6uxHQK9wwTcZUV-7w-vhUqOYy94X17K_cBO89Fut51qH_mDypu54OBYaQGZ_3s4pQW0wfzROMEnpeBoFu5IUcKCQPd9hQkiCSbt3rKyBtUPCRYZXhvGQcajqli2NsR35r3ojN3BWgwZgeZPHP-MOuROd_tB_BvqR-oyUpwOsRc9GvjHBR-wd1qiTics8WU2NREyZedaK5pjXc7bdxKrTfmfXrjCp1HT7KplHgjrT0d8tp8Kei3aflmT9f2akGTpJf7vJpw_l7qbPgWP9Eexx-oKHpsC0JX43nXG0vXgjYvLz8NhULeivxo4GfAIXOe-Q-AIgtcIEV8k7Q7l49_bdH55zwIPz2xd9u36iMsdXHG2POJYC1lO0YuYRWFe7SGihONGvMnsk-Ay4DlkD844RXNkzWIpg2ngW6MwYkvi64ecIn37l_3MuUOQP-x1eBfYezcTYLG7VBkkEXiRXO9ML0F7hulfRoyhwqUqdbNoDXDTovE0j9yRr5rfxCAQIYnmOquHml3fBf15zY4MWkjI7Mozwy_kQCYoJ9orOj6mvSqU8_eXwz83EbFMhtOkkOriBiwteaE_Dqh4WcCHq_07rihNs525oQJmSpENL2NnCrYXX-8Z3gI7dR94bgOHhzHVWf6sOISzbpLY5gZM-yF1tePs-Inta3aoc7GVjkzqZiNMVT4AkV4L9cx9ClSwzKGlpXOavax2h8nK9EijGOZ9KrIyyfrNSnMNVffRZwLdyyL6GhHClwCALVoerPzUF2D1SEnxDN2s1RwtiBSIF1YfI9xKYRXou1KOkxdILQyJH4vKzR7EL9VBVZUSg3zHkUTfiY6PQRMYKdkadUw9sbA21kqwG5p6XOEWzrfCdFeHv-Gh4ifshttoFL20_9FX3PxCpzz7iRPa5aL39t5YWhOp-t2nWeQx1Wf1SyGeA7LU3K4gdVAyzlR4zonHuAuotouLcFdE4n_Ew9aW6Y84cZTyAHS1TNXVbvEpirO_ywVGFGjJeBa-0O_mIhJBXuLph6WLFx5RMfdjDDnQ='\n",
    "\n",
    "print(decrypt(ans, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cc9d12-79c0-4a1c-a33e-136aa78fed6e",
   "metadata": {},
   "source": [
    "## Step 3. Compare some groups \n",
    "\n",
    "### First comparison - some arbitrary cut points. \n",
    "Let's create some groups and look at the scores within these groups. This is a comparison of means (which is a pre-cursor to a `t-test` which asks \"these means have different numbers, but are they _significantly_ different\". You do not have to do a t-test here, just report the mean differences. \n",
    "\n",
    "We are using somewhat arbitrary cut-points. Cut the data to all movies with a rating of 8 or more to all movies with a rating of 5 or less. \n",
    "\n",
    "Then we can ask, do higher rated movies have a shorter or longer runtime than lower rated movies? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20381282-5cc4-417a-a5fc-58f52e609acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this data set are 5610 movies with an average score of 8 or more.\n",
      "These movies have an average runtime of 129.88 minutes.\n",
      "In this data set are 5060 movies with an average score of 5 or less.\n",
      "These movies have an average runtime of 98.18 minutes.\n"
     ]
    }
   ],
   "source": [
    "above8 = movie_df[movie_df[\"averageRating\"] > 8]\n",
    "num_above8 = above8.size\n",
    "avg_above8 = above8[\"runtimeMinutes\"].mean()\n",
    "\n",
    "below5 = movie_df[movie_df[\"averageRating\"] < 5]\n",
    "num_below5 = below5.size\n",
    "avg_below5 = below5[\"runtimeMinutes\"].mean()\n",
    "\n",
    "\n",
    "print(f\"In this data set are {num_above8} movies with an average score of 8 or more.\")\n",
    "\n",
    "print(f\"These movies have an average runtime of {avg_above8:0.2f} minutes.\")\n",
    "\n",
    "print(f\"In this data set are {num_below5} movies with an average score of 5 or less.\")\n",
    "\n",
    "print(f\"These movies have an average runtime of {avg_below5:0.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76493106-ca43-4f1a-94d6-288eaffcd0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = b'gAAAAABh6UkhBWikSoloTo-xjoGch1v1aWxtbsvOB5h1F594T_Z0_y346UE66HJGm819Qu9K8HoelHN5y7drCw1F5I--WRaxQdkkKSZSBMwNDI_EzaNYlMX-7yIdJKR-noLjNs8kgRXSQ4Vp6a38X1gXwdoDMqpCLlKu8gA6o1pRDjptbBDp8CNiloK93RKCZrMKkfh1O7Pp640SRWCKAZ0UY8oIRmpr77sdh9n9fxULf_g-8nCUswqO1qGJytHITSmT1UODQP76Op7NOqTEViguuweELUd5Zzv8KPvwvGaMwi1dKoPzGrvfMaUkKrd6v6CQ7iMwkijL4gXkndFaC7_3nV3dDEEUsnf41pN6CEiqOZnMu1srpwW_OWbmVnwwD5MGR9f_fxJHXVXrJHo8D-m4SJSjgyHrSbzLn_1mY4m1PPrOnfnjpyEAHBWVgttK-t7qRlhwjYW7b_9hvtITVk9zv9_ga18UUYtEscl0ep0Hy-u0fejkraZfgt1aYX7khDldH-wEH4RH3hac-Zq2TLxKLJg7udp0g1Dj_522LR9qUVIBHkbDNwcTr-YXpm5K8WUbbYvh3Z6w3lWjJdYD1tvO0SOUw2NSiudbK06o0qwi4sTBxmVS1dIzDgxoGlxxfdVGOtj8JfhRXXsTSZ9uJlOnHI9Nh_Kuk80Y2LQJHZu3ciYVCQ7nNiqbo8l2zhbR7rKHwyqZPKYDmAhBrsXI3YzB-g6uKqdCPyU0ApxOSCSe8uCeQxrumfo_PGHwPA2iE3KtKsjhJD6HKcjyS68EhFeQBqgKMiC7bhuw9E1PZQwabUDVuAfX3gnjXT975AT93WnkJ2xBzHL9'\n",
    "\n",
    "print(decrypt(ans,key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0f5f5b-cde3-4503-943f-b5f0429973d5",
   "metadata": {},
   "source": [
    "### Second comparison - between genres\n",
    "\n",
    "The data have three genre columns. Compare the ratings of movies in the `'Comedy'` genre to those in the `'Drama'` genre. The simplest way would be to mask by `[movie_df.genre1 == 'Comedy']`. But what about the other two columns? Sometimes movies are classed as 'Comedy' and 'Western'.\n",
    "\n",
    "How might you account for those?  Here's a hint: if you have two columns to put in your comparison statement, you put them each in their own parenthesis and then use `|` as the *OR* symbol (as well as `&` for the _AND_ symbol). So we might say:\n",
    "\n",
    "~~~ python\n",
    "short_or_long = movie_df[(movie_df.runtimeMinutes < 90) | (movie_df.runtimeMinutes > 180)]\n",
    "long_and_bad = movie_df[(movie_df.runtimeMinutes > 150) & (movie_df.averageRating < 6)]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2dfbecd-6bb5-4584-9027-0a120af3a420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the data set there were 38984 Comedy movies.\n",
      "They had an average score of 6.5.\n",
      "In the data set there were 59268 Drama movies.\n",
      "They had an average score of 6.9.\n"
     ]
    }
   ],
   "source": [
    "# Create one genre column with all genres concatenated\n",
    "movie_df[\"genre\"] = movie_df[\"genre1\"] + movie_df[\"genre2\"].fillna(\"\") + movie_df[\"genre3\"].fillna(\"\")\n",
    "\n",
    "comedy = movie_df[movie_df[\"genre\"].str.contains(\"Comedy\")]\n",
    "num_comedy = comedy.size\n",
    "avg_comedy = comedy[\"averageRating\"].mean()\n",
    "\n",
    "drama = movie_df[movie_df[\"genre\"].str.contains(\"Drama\")]\n",
    "num_drama = drama.size\n",
    "avg_drama = drama[\"averageRating\"].mean()\n",
    "\n",
    "print(f\"In the data set there were {num_comedy} Comedy movies.\")\n",
    "print(f\"They had an average score of {avg_comedy:0.1f}.\")\n",
    "\n",
    "print(f\"In the data set there were {num_drama} Drama movies.\")\n",
    "print(f\"They had an average score of {avg_drama:0.1f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8b860d-a1a3-4c12-80dd-3ac81df379a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = b'gAAAAABh6Une6ifsZylGBSvBLkJvbqYy1oMtajxVva10OsyTaXqvt3S5UwzvSCG6ei2GTS1Z2hiweFSyKG4WZna5er5hbvKIlaCsA_AU3XNsGrKINA_RnA1028vSnlobRBK1dcY3TXmwYUIE6k1a_N5v_WboCxfO8mCvVg4Y2KGTS4cIqc-Ct-adKd8W1xXsOjgFscg7ZB847FZsIZ5idqM9heQH7BOIWK3j_cyBn9Fg0zaYVJK5zrrhXDFwBU9O9AXSjRjRLmwM6tjkeIWQ2zAHpNWWd29JYD60sSPuuSvDH4sWia0cOAek13p_eMIG5EDCyg_kAAB1od2dIz2MMH5tagpAYy7hiXyEALQ0aFfkUoW9PBPSm4RhpcBLxgTYX7wDOeOoufg28z7cewS-KzyEFbC6SxueT_6S1niD0Bw1OVu94dAw-lmilIkHy3zEHZg8K-aVVpyVWGl7ypGRqpaMEJKmxHl5w_fx1itZXF7mCGsV7ExAodn_tMhnWrYOao61XU1er8MRJe4sM5alwf1NhEaRl_01BnjLlNcG4BaSIq4UxOmH1C8xqc3X8cr6obAYcjORUUMhqZhg75UCKMXL-YmG-rkBxiYePJU16QizlfoxkRxxSEk-F_qQMUTXdBa7pRl0NOFGYb3ffL78GfGOIMkFhsv_2VKsGK5jn7aKeow2QXac0kaCEtfPWuicvbSkkn-wzbWrJmIxEojQv2vWHYQc_zJ12VFvvcSi3ll0X8CWytvmFZdCeUDB6Kzg7cTi5oydjd290QuQxc5-iTf0yQFmoYQeB9rbL7RuAPij1AbIW64Pt_uY2PxtsIa3JKfDGwZrU1Whm1w4klp-ul8mb4otNmMWZJun62atQ53h01FzavbSMXqAcxs3gjqMfmHQfYutyvFAvYnpGGUUE--styNui6PvFMyq9QGaOuFBqzlRKn1dXo-B0moVpeTXM4M4yiI-wlYreeAiUrZEt3b_vnvsrtuKWlh1MHfCcHP4kOy-4AI3aSrgnYAEJdJMI_bse0f0WtRKWyYWsj9-xsBunH4G2-BCofQGfF1h2pjuxhX-9k3BfXPM3lRR8isllY_RBcwIg-Jb1FFpoNDWOQ6pG_zYiEV3fg_eo8xdWLIpx2DJ1UqjkFYOnpH6iU8JmmU9wJyjafHFPi-W6tfila1BLbD9Ddy7dr2Vb8MBXE4ItTe22nVP3ASTZ_59PYFCXdCM8g9Gbj4xmRcn-hg6DWK9i4VD3Sbe1xFih5kOmYXHh3NTpVcxxirPSLQPzBBwE7w4SHUMp1I3y1tpptsWCC6vyuPMy62TSQdhWrfigX2i5kFUBJGUQlU5m7XjNvCWcJP63wcv-LzYVNamG6JKttO-Jfo2uoPDAMaH0uaX3Kok2DfzYotk5czRVJlMBrmFZQx5FHgpP59Ouf6i6t9CS6vf8B0AxqZY9B1Bbvm_BVPqzLThLD97Uq8='\n",
    "\n",
    "\n",
    "print(decrypt(ans,key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc89e8-9c87-48b4-9e72-b77a16c95fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests \n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "def encrypt(message: str, key: bytes) -> bytes:\n",
    "    return Fernet(key).encrypt(message.encode())\n",
    "\n",
    "def decrypt(token: bytes, key: bytes) -> str:\n",
    "    if not key: \n",
    "        return \"Please wait for the key - try these on your own!\"\n",
    "    return Fernet(key).decrypt(token).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e4b02b-d8e9-4593-9657-dec45bb97f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note these are not encrypted below\n",
    "key = b'fundamentalsofsocialdatasciencemichaelmas22_' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1791cd5f-5181-4132-b5cb-3e24ea1e4ab3",
   "metadata": {},
   "source": [
    "# The long question: Build a query machine \n",
    "\n",
    "For this long question you are asked to build and submit (either here in a cell or as a separate .py file) a script that will allow someone to query a data frame using text. \n",
    "\n",
    "Below are some skeleton code to help you get going. You will notice that currently you can:\n",
    "- Enter a verb, shape, and variable which will be parsed.\n",
    "- Two verbs have been implemented: `loadcsv` which will load a csv as a DataFrame and `exit` which will exit the program. \n",
    "- Please create a means to use the verb \"get\" to return a row, a column, or a single cell.\n",
    "\n",
    "1. Please create a means to use \"set\" to set the value of a single cell \n",
    "2. Please create a means to use \"list\" to display either the columns, number of rows, or describe the DataFrame.\n",
    "3. Please add two more features as an action. At least one of these should somehow interact with the DataFrame. Please be creative here. \n",
    "4. Give the program a welcome message that describes what you can do.\n",
    "5. Get the program a secret 'easter egg' action (such as typing \"happy\" to randomly print an inspirational message). \n",
    "\n",
    "Given that you can test this with the IMDB data and we created some interesting queries up above, perhaps think of a way to ask more involved questions or have the user select a question to answer from a set of canned questions.\n",
    "    \n",
    "Part of this task concerns how you take the basic DataFrame actions and link them together in Python methods (and maybe even Python objects). The use of `while` and a text input allows you to test program flow and some logic of looping. \n",
    "\n",
    "If you have explored object oriented program, there are a few ways to consider objects here but creating a new object or class isn't necessary.\n",
    "\n",
    "Rubric: \n",
    "Functioning: \n",
    "- Can use get (for row 1pt, for col 1pt, for cell 1pt)\n",
    "- Can use set (for cell 1pt)\n",
    "- Can exit (1pt)\n",
    "- Can loadcsv (1pt, note we will use a different csv to test)\n",
    "- Can list row length (1pt), column names (1pt)\n",
    "- Additional action 1. Should be using the DataFrame (2pts)\n",
    "- Additional action 2. (either on DF or elsewise, 2pts)\n",
    "- Does have easter egg (1pt)\n",
    "- Does have intro and/or help page (1pt)\n",
    "Robust:\n",
    "- Handles bad input gracefully (2pts)\n",
    "- Methods have at least a single comment explaining purpose (1pt)\n",
    "Elegant:\n",
    "- Has actions separated usefully into methods. (1pt)\n",
    "- Has other refactoring (subjective, 2pts)\n",
    "Creative: \n",
    "- Be creative. This might involve a useful help message, some interesting feature, or a refactoring that uses novel components. (5pts)\n",
    "\n",
    "That's 20 points total plus 5 points for creativity. It's hard to mark, so please treat mark as advisory. It does not count towards your summative mark.\n",
    "\n",
    "Qualitative assessment: \n",
    "- The TA may also write a short comment (1-2 sentences usually) describing the project and any potential mishaps or suggestions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ee9deb",
   "metadata": {},
   "source": [
    "# NB: My Solution is in the `class3_pandasexplorer.py` file! (below is pure Bernie :))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cec9704c-9197-4ca6-ab00-c745fe6afec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please make a selection\n",
      "Please make a selection\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "verbs = [\"get\",\"set\",\"loadcsv\",\"list\",\"exit\"]\n",
    "shapes = [\"row\",\"column\",\"cell\", \"df\"]\n",
    "\n",
    "def parse_text(text):\n",
    "    '''returns text separated by space'''\n",
    "    text_list = text.split()\n",
    "    text_phrase = {\"verb\":None,\"shapes\":None,\"var\":None}\n",
    "    \n",
    "    for i in verbs: \n",
    "        if i in text_list:\n",
    "            if text_phrase[\"verb\"] != None:\n",
    "                print(\"A statement should only have one verb\")\n",
    "                return None\n",
    "            text_phrase[\"verb\"] = i\n",
    "            text_list.pop(text_list.index(i))\n",
    "    \n",
    "    for i in shapes: \n",
    "        if i in text_list:\n",
    "            if text_phrase[\"shapes\"] != None:\n",
    "                print(\"A statement should only have one verb\")\n",
    "                return None\n",
    "            text_phrase[\"shapes\"] = i\n",
    "            text_list.pop(text_list.index(i))\n",
    "\n",
    "    if len(text_list) == 1: \n",
    "        text_phrase[\"var\"] = text_list[0]\n",
    "    \n",
    "    return text_phrase\n",
    "\n",
    "# def get_row(df, row):\n",
    "\n",
    "# def get_col(df, col): \n",
    "\n",
    "# def list_cols(df):\n",
    "\n",
    "# def set_cell(df):\n",
    "\n",
    "# def extra_func1(df):\n",
    "\n",
    "# def extra_func2(df): \n",
    "\n",
    "running = True\n",
    "while True: \n",
    "    print(\"Please make a selection\")\n",
    "    text = input()\n",
    "    if text == \"\": continue\n",
    "    \n",
    "    actions = parse_text(text)\n",
    "    if not actions: \n",
    "        print(\"Please try again or write type 'exit' to leave\")\n",
    "        continue\n",
    "    \n",
    "    # print(actions)\n",
    "    \n",
    "    if actions[\"verb\"] == \"exit\":\n",
    "        break\n",
    "    elif actions[\"verb\"] == \"loadcsv\":\n",
    "        df = pd.read_csv(actions[\"var\"])\n",
    "        print(f\"The DataFrame is loaded. It has {len(df)} rows\")\n",
    "\n",
    "# Note: loadcsv ../data/imdb_over10k_votes_movies.csv \n",
    "#       will work if your data is in a sibling folder called 'data'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('waldo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "3728cfcf275f18009e83b3c060135d2ac0dcb2409e2f4caa1bbd460837734472"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
