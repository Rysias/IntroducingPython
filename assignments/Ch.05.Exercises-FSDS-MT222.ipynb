{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "911e631a-74e8-44d7-861b-5686cf7941d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Week 2. Day 2. Exercises from Chapter 5 of FSStDS. \n",
    "## Fundamentals of Social Data Science. MT 2022\n",
    "\n",
    "Within your study pod discuss the following questions. Please submit an individual assignment by 12:30pm Wednesday, October 18, 2022 on Canvas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89c9dcec-3146-4555-8006-ca5bfde974a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01be37bb-7113-435b-a64a-58e95de39aa8",
   "metadata": {},
   "source": [
    "# Exercise 1. Twitter merging \n",
    "\n",
    "I have provided two tables: `dalle2_oct18_2022_tweets.csv` and `dalle2_oct18_2022_users.csv`. You can see how these tweets were collected in the Appendix to this assignment. It's a simple pull of only 100 tweets. To continue this pull would require paging (another day). For now, let's focus on merging. Please merge these two tables. \n",
    "\n",
    "Some tips: \n",
    "- Ensure that you keep all the tweets.\n",
    "- Ensure that the names which might overlap (hint...`id`) are given descriptive suffixes.\n",
    "- Your resulting df should still have 100 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e7f75ed-ea4d-4439-bf70-887b9769d9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 79 100\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1 below here \n",
    "\n",
    "def read_tweets(file_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Reads a json file to pandas dataframe\"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return pd.json_normalize(data)\n",
    "\n",
    "\n",
    "tweet_df = read_tweets(next(Path(\"../data\").glob(\"*tweets.json\")))\n",
    "users_df = read_tweets(next(Path(\"../data\").glob(\"*users.json\")))\n",
    "merge_df = pd.merge(tweet_df, users_df, left_on=\"author_id\", right_on=\"id\", how=\"left\", suffixes=(\"_tweet\", \"_user\"))\n",
    "\n",
    "print(len(tweet_df),len(users_df),len(merge_df))\n",
    "# Should be 100 79 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bc4cfa-88bb-41e5-b8f8-abd55655fe56",
   "metadata": {},
   "source": [
    "# Exercise 2. Twitter analytics \n",
    "\n",
    "Split the data into two groups: \n",
    "- Those with more than 1000 followers and those with less\n",
    "- Compare the two groups. Which group has more tweets and _proportionately_ more @mentions in their tweets.\n",
    "    \n",
    "> Note: Getting the @mentions can be done cheap and easy (search for @ symbol) or more robust and with a little more difficulty (look in the entities.mentions column and wrangle the dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05260ba5-314f-4c49-a808-5d64c926c3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of tweets from those with over 1k followers that have mentions is 24.1% The percentage of tweets from those with under 1k followers that have mentions is 11.3%\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2. Answer below here\n",
    "over1k = merge_df[\"public_metrics.followers_count\"] > 1000\n",
    "over1k_pctmention = merge_df.loc[over1k, \"entities.mentions\"].notna().mean()\n",
    "under1k_pctmention = merge_df.loc[~over1k, \"entities.mentions\"].notna().mean()\n",
    "\n",
    "print(f\"The percentage of tweets from those with over 1k followers that have mentions is {over1k_pctmention:0.1%} \"\n",
    "      f\"The percentage of tweets from those with under 1k followers that have mentions is {under1k_pctmention:0.1%}\")\n",
    "\n",
    "# Should be 29 for over1k and 71 for under1k\n",
    "# And therefore should be 24.1% and 11.3% respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34247d4-c4d5-47bf-87f3-9d1ed57ff041",
   "metadata": {},
   "source": [
    "# Exercise 3. Grouping the data\n",
    "\n",
    "Group the data by Author and build a table that reports the max, min, and average for both  `public_metrics.retweet_count` and `public_metrics.like_count`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f4af2e-b53c-49d5-8f57-12a9c4290255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">public_metrics.retweet_count</th>\n",
       "      <th colspan=\"3\" halign=\"left\">public_metrics.like_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1075759307659063296</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11085112</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246388877713178624</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256547797567930370</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318265150059708416</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780746497017032704</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782162190518263808</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814009956261203968</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924431378</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950233834888478722</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    public_metrics.retweet_count           \\\n",
       "                                             max min mean   \n",
       "author_id                                                   \n",
       "1075759307659063296                            1   1  1.0   \n",
       "11085112                                       0   0  0.0   \n",
       "1246388877713178624                            1   1  1.0   \n",
       "1256547797567930370                            4   4  4.0   \n",
       "1318265150059708416                            0   0  0.0   \n",
       "...                                          ...  ..  ...   \n",
       "780746497017032704                             0   0  0.0   \n",
       "782162190518263808                             0   0  0.0   \n",
       "814009956261203968                             1   1  1.0   \n",
       "924431378                                      0   0  0.0   \n",
       "950233834888478722                             0   0  0.0   \n",
       "\n",
       "                    public_metrics.like_count            \n",
       "                                          max min  mean  \n",
       "author_id                                                \n",
       "1075759307659063296                         4   4   4.0  \n",
       "11085112                                    0   0   0.0  \n",
       "1246388877713178624                         1   1   1.0  \n",
       "1256547797567930370                        10  10  10.0  \n",
       "1318265150059708416                         1   1   1.0  \n",
       "...                                       ...  ..   ...  \n",
       "780746497017032704                          2   0   1.0  \n",
       "782162190518263808                          5   5   5.0  \n",
       "814009956261203968                          4   4   4.0  \n",
       "924431378                                   3   2   2.5  \n",
       "950233834888478722                          0   0   0.0  \n",
       "\n",
       "[79 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 3. Answer below here\n",
    "merge_df.groupby(\"author_id\")[[\"public_metrics.retweet_count\", \"public_metrics.like_count\"]].agg([\"max\", \"min\", \"mean\"])\n",
    "# Should be one line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33a1ae9-36bc-49a0-9de8-c7c6e11cfd34",
   "metadata": {},
   "source": [
    "# Exercise 4. Twitter Reshaping\n",
    "\n",
    "Create a long `DataFrame` of tweet_ids, author_ids, and hash_tags. That is, one row per hashtag rather than one per tweet. Report the length of this `DataFrame` and the `value_counts()` of the top 10 hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c1d9fa-04d7-4f0f-a143-09ff826335c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_taglist(tag_list_full: Optional[List[Dict[str, str]]]) -> List[str]:\n",
    "    if type(tag_list_full) is not list:\n",
    "        return []\n",
    "    return [x['tag'] for x in tag_list_full]\n",
    "\n",
    "new_df = merge_df.copy()\n",
    "new_df['tags'] = new_df['entities.hashtags'].map(get_taglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdb9a699-2086-4d29-ac11-44b79e2ac4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the exploded data by hashtag is 608\n",
      "The top ten hashtags are as follows:\n",
      "dalle2             77\n",
      "aiart              25\n",
      "ai                 25\n",
      "dalle              23\n",
      "stablediffusion    22\n",
      "midjourney         22\n",
      "digitalart         20\n",
      "AIart              14\n",
      "aiartist           13\n",
      "aiartcommunity     12\n",
      "Name: tags, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "long_df = new_df[['id_tweet','tags','username']].explode('tags')\n",
    "\n",
    "print(f\"The length of the exploded data by hashtag is {len(long_df)}\")\n",
    "print(\"The top ten hashtags are as follows:\",\n",
    "       long_df['tags'].value_counts()[:10],\n",
    "      sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adcec63-0ec5-41f0-ba0c-adb2b8c11a35",
   "metadata": {},
   "source": [
    "# Appendix: How I pre-processed the data (See Chapter 7) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4039821-6b19-4efa-9836-c9daed949566",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m ENV_PATH \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m..\u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39msep\u001b[39m}\u001b[39;00m\u001b[39m.env\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m dotenv\u001b[39m.\u001b[39mload_dotenv(ENV_PATH) \u001b[39m# This will refresh the environment variables\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39;49m(os\u001b[39m.\u001b[39;49menviron\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mTWITTER_BEARER_TOKEN\u001b[39;49m\u001b[39m'\u001b[39;49m)))\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import dotenv\n",
    "\n",
    "ENV_PATH = f\"..{os.sep}.env\"\n",
    "dotenv.load_dotenv(ENV_PATH) # This will refresh the environment variables\n",
    "print(len(os.environ.get('TWITTER_BEARER_TOKEN')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2158340c-7d8c-42a2-a9a8-49c56cfb3abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'includes', 'meta'])\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://api.twitter.com/2/tweets/search/all\"\n",
    "\n",
    "BEARER = os.environ[\"TWITTER_BEARER_TOKEN\"]\n",
    "headers = {\"Authorization\": f\"Bearer {BEARER}\"}\n",
    "\n",
    "QUERY = \"(dalle2) -is:retweet\"\n",
    "MAX_RESULTS = 100 \n",
    "\n",
    "params={\"query\": QUERY,\n",
    "        \"max_results\":MAX_RESULTS}\n",
    "\n",
    "params['expansions'] = \"author_id,geo.place_id\"\n",
    "params['tweet.fields'] = \"entities,public_metrics\"\n",
    "params['user.fields'] = \"id,username,name,description,public_metrics\"\n",
    "params['place.fields'] = \"id,country,country_code,full_name\"\n",
    "\n",
    "response = requests.get(URL, headers=headers, params=params)\n",
    "\n",
    "assert response.status_code == 200, \\\n",
    "    f\"Code {response.status_code}. See error: {response.json()}\"\n",
    "\n",
    "tweets = response.json()\n",
    "print(tweets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a38bf-4c3a-42cd-a5d5-6c8faf159785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "json.dump(tweets['data'], \n",
    "          open(\"dalle2_oct18_2022_tweets.json\",'w')) \n",
    "\n",
    "json.dump(tweets['includes']['users'],\n",
    "          open(\"dalle2_oct18_2022_users.json\",'w')) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sdspython')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "vscode": {
   "interpreter": {
    "hash": "60612d6d4782d833a44515694e4bccfae5bb8e3209e7562cc1fda167f2433927"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
