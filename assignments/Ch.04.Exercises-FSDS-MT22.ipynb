{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9d7bac-c8a9-4221-9d42-0b91d8f05a00",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Week 2. Day 1. Exercises from Chapter 4 of FSStDS. \n",
    "## Fundamentals of Social Data Science. MT 2022\n",
    "\n",
    "Within your study pod discuss the following questions. Please submit an individual assignment by 12:30pm Tuesday, October 18, 2022 on Canvas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0803932b-ef93-4423-970d-fd1d20f5c82a",
   "metadata": {},
   "source": [
    "# Exercise 1. Creating a DataFrame from multiple JSON files\n",
    "\n",
    "There are nine pages of search results for Oxford from OMDB (as of last year; `omdb_Oxford_search_page_\\*.json`). \n",
    "\n",
    "**Exercise 1a.** Create a single DataFrame from these 9 files.\n",
    "\n",
    "**Exercise 1b.** Report on the oldest and most recent entry. \n",
    "\n",
    "- **Hint**. To read all files from a Path object with a wildcard use the 'glob' method, such as: `for path in data_dir.blog(\"omdb_Oxford*.json\"): path.do_something()`\n",
    "\n",
    "- **Challenge** - Note that shows that span years are written with the two years separated by `--`. So ensure that you split this and then consider these years when reporting the oldest and newest entries. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5964f5b7-64a6-4bf6-b331-b38c7e4e90f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1a answer below here \n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path \n",
    "\n",
    "def read_json(json_file: Path) -> pd.DataFrame:\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return pd.DataFrame(data[\"Search\"])\n",
    "\n",
    "\n",
    "data_dir = Path(\"../data/Week2Day1 - Exercsie Data for the data folder\")\n",
    "assert data_dir.exists()\n",
    "\n",
    "# Read the files from json\n",
    "df = pd.concat([read_json(f) for f in data_dir.glob(\"*omdb_Oxford_search_page_*.json\")])\n",
    "# Exercise 1a answer above here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6da13185-3935-4c3b-b45b-12605ff78a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oldest entry: The Oxford and Cambridge University Boat Race (1895)\n",
      "Newest entry: Ein Sommer in Oxford (2018)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1b answer below here \n",
    "df[\"Year\"] = df[\"Year\"].str.extract(r\"(\\d{4})\").astype(int)\n",
    "oldest_entry = df[df[\"Year\"] == df[\"Year\"].min()]\n",
    "newest_entry = df[df[\"Year\"] == df[\"Year\"].max()]\n",
    "print(f\"Oldest entry: {oldest_entry['Title'].values[0]} ({oldest_entry['Year'].values[0]})\")\n",
    "print(f\"Newest entry: {newest_entry['Title'].values[0]} ({newest_entry['Year'].values[0]})\")\n",
    "# Exercise 1b answer above here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ed32db-97d9-4a31-9622-b1a654dd79d6",
   "metadata": {},
   "source": [
    "# Exercise 2. Navigate Reddit JSON \n",
    "\n",
    "Go to a page on reddit and then replace www.reddit with api.reddit. This will then give the page as JSON. Do this for a specific subreddit of interest (such as cats, cryptocurrency, mediasynthesis, ukpolitics, etc...). \n",
    "\n",
    "This json will likely only have 25-26 entries. Normalise by data so that each story has a single line. This will have many, many columns. One of these columns will be the title of the headline and one will be the URL. \n",
    "\n",
    "- **Exercise 2a**. Find these two columns and then create a smaller DataFrame that just has these columns as well as the one for upvote score (`ups`).  \n",
    "\n",
    "- **Exercise 2b**. What are the most common words across all titles? Does it matter if you use lower case and remove punctuation as we did last week? \n",
    "\n",
    "- **Exercise 2c**. What domain names are the most common?\n",
    "\n",
    "> **Hint**: If you aren't having luck with saving your own JSON, you can use the old `environment.json` that is appended with the data. \n",
    "\n",
    "> **Hint**: Parsing domain names can be a nuisance. Here is a a small snippet that can help: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "750c3cb3-1f0c-41f9-b9c9-32ee0d180e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParseResult(scheme='http', netloc='www.nytimes.com', path='/somestory.html', params='', query='', fragment='')\n"
     ]
    }
   ],
   "source": [
    "# See: https://docs.python.org/3/library/urllib.parse.html\n",
    "# For example:\n",
    "from urllib.parse import urlparse\n",
    "result = urlparse(\"http://www.nytimes.com/somestory.html\")\n",
    "print(result) # Which item is the domain name? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cad7d8ff-ebcb-4c8f-a4bc-33ea9a7bc810",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [49], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m reddit_url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://api.reddit.com\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m wholesome_url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mreddit_url\u001b[39m}\u001b[39;00m\u001b[39m/r/wholesomememes/top?t=day&limit=100\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 13\u001b[0m new_df \u001b[39m=\u001b[39m read_results(wholesome_url, columns\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mtitle\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39murl\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mups\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "Cell \u001b[1;32mIn [49], line 8\u001b[0m, in \u001b[0;36mread_results\u001b[1;34m(url, columns)\u001b[0m\n\u001b[0;32m      6\u001b[0m r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url)\n\u001b[0;32m      7\u001b[0m results \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mjson()\n\u001b[1;32m----> 8\u001b[0m \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mDataFrame([data[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m results[\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39m\u001b[39mchildren\u001b[39m\u001b[39m\"\u001b[39m]])[columns]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'data'"
     ]
    }
   ],
   "source": [
    "# Exercise 2a Answer below here \n",
    "from typing import List\n",
    "import requests\n",
    "\n",
    "def read_results(url: str, columns: List[str]) -> pd.DataFrame:\n",
    "    r = requests.get(url)\n",
    "    assert r.status_code == 200, f\"Request failed with status code {r.status_code}\"\n",
    "    results = r.json()\n",
    "    return pd.DataFrame([data[\"data\"] for data in results[\"data\"][\"children\"]])[columns]\n",
    "\n",
    "reddit_url = \"https://api.reddit.com\"\n",
    "wholesome_url = f\"{reddit_url}/r/wholesomememes/top?t=day&limit=100\"\n",
    "\n",
    "new_df = read_results(wholesome_url, columns=[\"title\", \"url\", \"ups\"])\n",
    "\n",
    "\n",
    "# Exercise 2a Answer above here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46a691ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>ups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Look at his smile :)</td>\n",
       "      <td>https://i.imgur.com/H9tgQ0x.png</td>\n",
       "      <td>73067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Still friends 37 years later 💜</td>\n",
       "      <td>https://i.redd.it/er7dsw87b8u91.jpg</td>\n",
       "      <td>70680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He is the chosen one</td>\n",
       "      <td>https://i.redd.it/i7zy6j11o6u91.jpg</td>\n",
       "      <td>19181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Important Update</td>\n",
       "      <td>https://i.redd.it/zp8an8p15au91.png</td>\n",
       "      <td>7717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is so true</td>\n",
       "      <td>https://i.redd.it/7prhc0hpq6u91.jpg</td>\n",
       "      <td>6739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Posted in daddit- Arnold Schwarzenegger replie...</td>\n",
       "      <td>https://i.redd.it/xq1aak0509u91.jpg</td>\n",
       "      <td>5254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Just some good wholesome fun</td>\n",
       "      <td>https://i.redd.it/j26exdyqj9u91.jpg</td>\n",
       "      <td>2699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Here's a strong coffee for a strong person jus...</td>\n",
       "      <td>https://i.redd.it/b9dmialjw7u91.jpg</td>\n",
       "      <td>2473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Innovative</td>\n",
       "      <td>https://i.redd.it/u13o8caiqbu91.jpg</td>\n",
       "      <td>2939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ok,I will keep them</td>\n",
       "      <td>https://i.redd.it/ilse6e6a86u91.gif</td>\n",
       "      <td>1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Getting away</td>\n",
       "      <td>https://i.redd.it/aff19qg6s5u91.jpg</td>\n",
       "      <td>1119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This is very wholesome to me</td>\n",
       "      <td>https://i.redd.it/x5lhhxh9cau91.jpg</td>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>It is the law.</td>\n",
       "      <td>https://i.redd.it/v62iocryg6u91.jpg</td>\n",
       "      <td>899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>You rise if you rest ✨🍞✨</td>\n",
       "      <td>https://i.redd.it/gz0vied7x7u91.jpg</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bridesmaids vibes</td>\n",
       "      <td>https://i.redd.it/nkp561dal8u91.jpg</td>\n",
       "      <td>733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sending Out Love &amp;lt;3</td>\n",
       "      <td>https://i.redd.it/h1bvwhjgw9u91.jpg</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>All hail Kit Kat!</td>\n",
       "      <td>https://i.redd.it/xsd3jukqr7u91.jpg</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sometimes bees get tired too ... 🐝</td>\n",
       "      <td>https://i.redd.it/b6xkylqotbu91.jpg</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Are ya winning dad?</td>\n",
       "      <td>https://imgur.com/1Fcuvs7.jpg</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dwagon ahh! :3</td>\n",
       "      <td>https://i.redd.it/kdqhtua2mbu91.jpg</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Wholesome One dollar</td>\n",
       "      <td>https://i.redd.it/bfgn0fu22ma71.jpg</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cute long boi</td>\n",
       "      <td>https://i.redd.it/wlqcsijnk7u91.jpg</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Me every time i leave my house.</td>\n",
       "      <td>https://i.redd.it/jkbpbawg78u91.jpg</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>We saw a funny squirrel</td>\n",
       "      <td>https://i.redd.it/dflmch80y8u91.gif</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Breathe in, breathe out.</td>\n",
       "      <td>https://i.redd.it/he42u6vca9u91.gif</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Team effort</td>\n",
       "      <td>https://i.redd.it/xyzrbkmvncu91.jpg</td>\n",
       "      <td>1552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>This is extremely nice</td>\n",
       "      <td>https://i.redd.it/1od6hcbya6u91.jpg</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>i never see it coming, but i always should... ...</td>\n",
       "      <td>https://i.redd.it/ht5rytnon7u91.jpg</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Here comes the cam</td>\n",
       "      <td>https://i.redd.it/rxg2mv4fm7u91.jpg</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Anatidaephobia more like....</td>\n",
       "      <td>https://i.redd.it/4zmstzqcg9u91.png</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Frog wisdom</td>\n",
       "      <td>https://i.redd.it/7e5brkej8bu91.jpg</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>they'll do anything to not break your heart</td>\n",
       "      <td>https://i.redd.it/chftxqtw88u91.png</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Daily Cute Kitten Photo. Day 5</td>\n",
       "      <td>https://i.redd.it/2vxkggg9u6u91.jpg</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Be like Bowser. Never give up!</td>\n",
       "      <td>https://i.redd.it/6x23ug472bu91.jpg</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Be kind to everyone</td>\n",
       "      <td>https://i.redd.it/9kfkdtoi4cu91.jpg</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Rat &amp;amp; A Snake</td>\n",
       "      <td>https://imgur.com/4vrD4S0.jpg</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Onto better days</td>\n",
       "      <td>https://i.redd.it/zlpcbodjvbu91.gif</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Sometimes their presence is just comforting</td>\n",
       "      <td>https://i.redd.it/1x5huzjp86u91.jpg</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Posting memes until I get my master's degree d...</td>\n",
       "      <td>https://i.redd.it/qijxd3cmw8u91.jpg</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Buddy Gator - Friendship</td>\n",
       "      <td>https://i.imgur.com/FKw1Uxv.jpeg</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Just in case you were wondering</td>\n",
       "      <td>https://i.redd.it/m2pukd8k1cu91.jpg</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>He knows my weakness</td>\n",
       "      <td>https://i.redd.it/8lywi9u5l7u91.jpg</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Wholesome Youtube!</td>\n",
       "      <td>https://i.redd.it/o3nzax2oecu91.jpg</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Saw this and made me smile</td>\n",
       "      <td>https://i.redd.it/l9xy5h14k8u91.jpg</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>it's corn 🌽🌽🌽</td>\n",
       "      <td>https://i.redd.it/gztsxu6p89u91.jpg</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>You are all lovely</td>\n",
       "      <td>https://i.redd.it/40ke46bxsbu91.jpg</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Oh my Doctor!</td>\n",
       "      <td>https://i.redd.it/5wlbfr0j86u91.jpg</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>mens in skinny jeans</td>\n",
       "      <td>https://i.redd.it/22duq7pwicu91.jpg</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Sign language in Italian 🇮🇹 🤌🏻🤌🏼🤌🏽🤌🏾🤌🏿</td>\n",
       "      <td>https://i.redd.it/5izf0r9tiau91.png</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>hoodies are comfy ngl</td>\n",
       "      <td>https://i.redd.it/chopvhs1x6u91.jpg</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                                Look at his smile :)   \n",
       "1                      Still friends 37 years later 💜   \n",
       "2                                He is the chosen one   \n",
       "3                                    Important Update   \n",
       "4                                     this is so true   \n",
       "5   Posted in daddit- Arnold Schwarzenegger replie...   \n",
       "6                        Just some good wholesome fun   \n",
       "7   Here's a strong coffee for a strong person jus...   \n",
       "8                                          Innovative   \n",
       "9                                 Ok,I will keep them   \n",
       "10                                       Getting away   \n",
       "11                       This is very wholesome to me   \n",
       "12                                     It is the law.   \n",
       "13                           You rise if you rest ✨🍞✨   \n",
       "14                                  Bridesmaids vibes   \n",
       "15                             Sending Out Love &lt;3   \n",
       "16                                  All hail Kit Kat!   \n",
       "17                 Sometimes bees get tired too ... 🐝   \n",
       "18                                Are ya winning dad?   \n",
       "19                                     dwagon ahh! :3   \n",
       "20                               Wholesome One dollar   \n",
       "21                                      cute long boi   \n",
       "22                    Me every time i leave my house.   \n",
       "23                            We saw a funny squirrel   \n",
       "24                           Breathe in, breathe out.   \n",
       "25                                        Team effort   \n",
       "26                             This is extremely nice   \n",
       "27  i never see it coming, but i always should... ...   \n",
       "28                                 Here comes the cam   \n",
       "29                       Anatidaephobia more like....   \n",
       "30                                        Frog wisdom   \n",
       "31        they'll do anything to not break your heart   \n",
       "32                     Daily Cute Kitten Photo. Day 5   \n",
       "33                     Be like Bowser. Never give up!   \n",
       "34                                Be kind to everyone   \n",
       "35                                  Rat &amp; A Snake   \n",
       "36                                   Onto better days   \n",
       "37        Sometimes their presence is just comforting   \n",
       "38  Posting memes until I get my master's degree d...   \n",
       "39                           Buddy Gator - Friendship   \n",
       "40                    Just in case you were wondering   \n",
       "41                               He knows my weakness   \n",
       "42                                 Wholesome Youtube!   \n",
       "43                         Saw this and made me smile   \n",
       "44                                      it's corn 🌽🌽🌽   \n",
       "45                                 You are all lovely   \n",
       "46                                      Oh my Doctor!   \n",
       "47                               mens in skinny jeans   \n",
       "48             Sign language in Italian 🇮🇹 🤌🏻🤌🏼🤌🏽🤌🏾🤌🏿   \n",
       "49                              hoodies are comfy ngl   \n",
       "\n",
       "                                    url    ups  \n",
       "0       https://i.imgur.com/H9tgQ0x.png  73067  \n",
       "1   https://i.redd.it/er7dsw87b8u91.jpg  70680  \n",
       "2   https://i.redd.it/i7zy6j11o6u91.jpg  19181  \n",
       "3   https://i.redd.it/zp8an8p15au91.png   7717  \n",
       "4   https://i.redd.it/7prhc0hpq6u91.jpg   6739  \n",
       "5   https://i.redd.it/xq1aak0509u91.jpg   5254  \n",
       "6   https://i.redd.it/j26exdyqj9u91.jpg   2699  \n",
       "7   https://i.redd.it/b9dmialjw7u91.jpg   2473  \n",
       "8   https://i.redd.it/u13o8caiqbu91.jpg   2939  \n",
       "9   https://i.redd.it/ilse6e6a86u91.gif   1414  \n",
       "10  https://i.redd.it/aff19qg6s5u91.jpg   1119  \n",
       "11  https://i.redd.it/x5lhhxh9cau91.jpg   1068  \n",
       "12  https://i.redd.it/v62iocryg6u91.jpg    899  \n",
       "13  https://i.redd.it/gz0vied7x7u91.jpg    834  \n",
       "14  https://i.redd.it/nkp561dal8u91.jpg    733  \n",
       "15  https://i.redd.it/h1bvwhjgw9u91.jpg    748  \n",
       "16  https://i.redd.it/xsd3jukqr7u91.jpg    695  \n",
       "17  https://i.redd.it/b6xkylqotbu91.jpg    800  \n",
       "18        https://imgur.com/1Fcuvs7.jpg    645  \n",
       "19  https://i.redd.it/kdqhtua2mbu91.jpg    624  \n",
       "20  https://i.redd.it/bfgn0fu22ma71.jpg    804  \n",
       "21  https://i.redd.it/wlqcsijnk7u91.jpg    496  \n",
       "22  https://i.redd.it/jkbpbawg78u91.jpg    485  \n",
       "23  https://i.redd.it/dflmch80y8u91.gif    483  \n",
       "24  https://i.redd.it/he42u6vca9u91.gif    403  \n",
       "25  https://i.redd.it/xyzrbkmvncu91.jpg   1552  \n",
       "26  https://i.redd.it/1od6hcbya6u91.jpg    385  \n",
       "27  https://i.redd.it/ht5rytnon7u91.jpg    299  \n",
       "28  https://i.redd.it/rxg2mv4fm7u91.jpg    268  \n",
       "29  https://i.redd.it/4zmstzqcg9u91.png    249  \n",
       "30  https://i.redd.it/7e5brkej8bu91.jpg    255  \n",
       "31  https://i.redd.it/chftxqtw88u91.png    240  \n",
       "32  https://i.redd.it/2vxkggg9u6u91.jpg    208  \n",
       "33  https://i.redd.it/6x23ug472bu91.jpg    199  \n",
       "34  https://i.redd.it/9kfkdtoi4cu91.jpg    188  \n",
       "35        https://imgur.com/4vrD4S0.jpg    156  \n",
       "36  https://i.redd.it/zlpcbodjvbu91.gif    173  \n",
       "37  https://i.redd.it/1x5huzjp86u91.jpg    152  \n",
       "38  https://i.redd.it/qijxd3cmw8u91.jpg    139  \n",
       "39     https://i.imgur.com/FKw1Uxv.jpeg    132  \n",
       "40  https://i.redd.it/m2pukd8k1cu91.jpg    138  \n",
       "41  https://i.redd.it/8lywi9u5l7u91.jpg    111  \n",
       "42  https://i.redd.it/o3nzax2oecu91.jpg    130  \n",
       "43  https://i.redd.it/l9xy5h14k8u91.jpg    104  \n",
       "44  https://i.redd.it/gztsxu6p89u91.jpg     95  \n",
       "45  https://i.redd.it/40ke46bxsbu91.jpg     83  \n",
       "46  https://i.redd.it/5wlbfr0j86u91.jpg     69  \n",
       "47  https://i.redd.it/22duq7pwicu91.jpg     75  \n",
       "48  https://i.redd.it/5izf0r9tiau91.png     61  \n",
       "49  https://i.redd.it/chopvhs1x6u91.jpg     56  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f567c630-eb57-4a00-b683-4095b33903b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2b Answer below here \n",
    "\n",
    "\n",
    "# Exercise 2b Answer above here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71d9d55f-93d0-417d-923e-f9ea61353061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2c Answer below here \n",
    "\n",
    "\n",
    "# Exercise 2c Answer above here "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3b17f7-d9b2-40ff-b569-7a5184786f44",
   "metadata": {},
   "source": [
    "# Exercise 3. The love-hate relationship with DIKW\n",
    "\n",
    "As mentioned in the chapter, the Wikipedia entry for data had DIKW in the article, then it was removed, then it reappared! I think it is still there now. I did not do the editing of this. \n",
    "\n",
    "With the data export of the Wikipedia page on data (`Wikipedia - data - Special export - 2022-10-17_10_24_15.xml`): \n",
    "\n",
    "- **Exercise 3a**. Create a DataFrame where each revision of the Wikipedia article in the export is given its own row. \n",
    "- **Exercise 3b**. Search for the first time DIKW was mentioned and the last time it was mentioned. Try to find the gap? When did it appear? \n",
    "\n",
    "> **Hint**: Using `xmltodict` might be helpful for wrangling the XML data, but it might also make life complicated. Explore the data both through a text editor (or browser) and through code to get a sense of it. \n",
    "\n",
    "> **Hint**: It is admittedly a little easier to do this if you make use of time in your DataFrame. We do not cover that much until Chapter 10, but feel free to look ahead. You can still sort by revisionID and then just browse the data yourself. This will end up being one of those tasks that's not easy but gets easier with more skills of abstraction.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544c55c4-5f10-4992-b11d-795d5eda84f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3a Answer below here\n",
    "\n",
    "\n",
    "# EXercise 3a Answer above here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb4d4201-a466-4fe1-9e35-0a29c43cd795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3b Answer below here\n",
    "\n",
    "\n",
    "# EXercise 3b Answer above here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sdspython')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "60612d6d4782d833a44515694e4bccfae5bb8e3209e7562cc1fda167f2433927"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
